services:
  app:
    image: mcr.microsoft.com/devcontainers/base:jammy
    build: 
      context: .
      dockerfile: Dockerfile
    environment:
      - OLLAMA_BASE_URL=http://host.docker.internal:11434
      - HF_HOME=/workspace/model
      - PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128,expandable_segments:True
    volumes:
      - ../:/workspace
      - /Users/oleggrynets/docs:/mnt/docs:ro
    command: sleep infinity
    networks:
      - langindex-net

networks:
  langindex-net:
